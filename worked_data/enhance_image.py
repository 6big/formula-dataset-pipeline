import os
import cv2
import numpy as np
import json
from pathlib import Path

def apply_enhancements(image, random_seed: int = None):
    """
    åº”ç”¨ Â±5Â° æ—‹è½¬å¢å¼º
    
    Args:
        image: OpenCV å›¾åƒæ•°ç»„
        random_seed: éšæœºç§å­ï¼Œç”¨äºå¤ç°ç»“æœ
    """
    if random_seed is not None:
        np.random.seed(random_seed)
    
    angle = np.random.uniform(-5, 5)
    
    if len(image.shape) == 3:
        h, w = image.shape[:2]
    else:
        h, w = image.shape
    
    center = (w // 2, h // 2)
    rotation_matrix = cv2.getRotationMatrix2D(center, angle, 1.0)
    
    # è®¡ç®—æ–°è¾¹ç•Œå°ºå¯¸
    cos_angle = abs(rotation_matrix[0, 0])
    sin_angle = abs(rotation_matrix[0, 1])
    new_w = int((h * sin_angle) + (w * cos_angle))
    new_h = int((h * cos_angle) + (w * sin_angle))
    
    # è°ƒæ•´å˜æ¢çŸ©é˜µä»¥ä¿æŒä¸­å¿ƒ
    rotation_matrix[0, 2] += (new_w / 2) - center[0]
    rotation_matrix[1, 2] += (new_h / 2) - center[1]
    
    enhanced = cv2.warpAffine(
        image, 
        rotation_matrix, 
        (new_w, new_h), 
        flags=cv2.INTER_NEAREST,
        borderMode=cv2.BORDER_REFLECT
    )
    
    return enhanced

def _get_images_from_jsonl(dataset_jsonl):
    """ä» JSONL æ–‡ä»¶è·å–å›¾ç‰‡åˆ—è¡¨çš„è¾…åŠ©å‡½æ•°"""
    jsonl_images = set()
    try:
        with open(dataset_jsonl, 'r', encoding='utf-8') as f:
            for line in f:
                if line.strip():
                    try:
                        data = json.loads(line.strip())
                        for img_path in data.get('images', []):
                            filename = os.path.basename(img_path)
                            jsonl_images.add(filename)
                    except json.JSONDecodeError:
                        continue
    except Exception as e:
        print(f"âš ï¸ è¯»å– JSONL æ–‡ä»¶æ—¶å‡ºé”™: {e}")
    return jsonl_images

def enhance_images_in_place(
    images_dir: str,
    dataset_jsonl: str = None,
    num_to_augment: int = None,
    augmentation_ratio: float = 0.1,
    enhance_strategy: str = "deterministic",
    backup_original: bool = False,
    random_seed: int = 42  # æ–°å¢ï¼šéšæœºç§å­
) -> str:
    """
    åŸåœ°å¢å¼ºå›¾ç‰‡ï¼ˆç›´æ¥æ›¿æ¢åŸå›¾ï¼‰
    
    Args:
        images_dir: å›¾ç‰‡ç›®å½•
        dataset_jsonl: å¯é€‰ï¼ŒJSONL æ–‡ä»¶è·¯å¾„
        num_to_augment: è¦å¢å¼ºçš„æ•°é‡
        augmentation_ratio: å¢å¼ºæ¯”ä¾‹
        enhance_strategy: å¢å¼ºç­–ç•¥
        backup_original: æ˜¯å¦å¤‡ä»½åŸå›¾
        random_seed: éšæœºç§å­ï¼Œç”¨äºç¡®å®šæ€§å¢å¼º
    """
    try:
        images_path = Path(images_dir)
        if not images_path.exists():
            return f"âŒ å›¾ç‰‡ç›®å½•ä¸å­˜åœ¨: {images_dir}"
        
        # æ”¯æŒçš„å›¾åƒæ ¼å¼
        supported_formats = {'.png', '.jpg', '.jpeg', '.bmp', '.tiff', '.gif'}
        
        # è·å–è¦å¤„ç†çš„å›¾ç‰‡åˆ—è¡¨
        if dataset_jsonl and Path(dataset_jsonl).exists():
            jsonl_images = _get_images_from_jsonl(dataset_jsonl)
            all_images = []
            for file in images_path.iterdir():
                if file.suffix.lower() in supported_formats and file.name in jsonl_images:
                    all_images.append(file.name)
            print(f"ğŸ” ä» JSONL è¯»å–åˆ° {len(jsonl_images)} ä¸ªå›¾ç‰‡å¼•ç”¨ï¼Œç›®å½•ä¸­æ‰¾åˆ° {len(all_images)} ä¸ªåŒ¹é…çš„å›¾ç‰‡")
        else:
            all_images = []
            for file in images_path.iterdir():
                if file.suffix.lower() in supported_formats:
                    all_images.append(file.name)
            print(f"ğŸ“ ç›®å½•ä¸­æ‰¾åˆ° {len(all_images)} ä¸ªå›¾ç‰‡æ–‡ä»¶")
        
        if not all_images:
            return f"âŒ ç›®å½•ä¸­æ²¡æœ‰æ‰¾åˆ°è¦å¤„ç†çš„å›¾ç‰‡æ–‡ä»¶"
        
        all_images.sort()
        
        # ç¡®å®šè¦å¢å¼ºçš„å›¾ç‰‡ç´¢å¼•ï¼ˆè®¾ç½®éšæœºç§å­ç¡®ä¿ç¡®å®šæ€§ï¼‰
        np.random.seed(random_seed)
        total_images = len(all_images)
        
        if enhance_strategy == "all":
            indices_to_augment = set(range(total_images))
        elif enhance_strategy == "random":
            if num_to_augment is None:
                num_to_augment = int(total_images * augmentation_ratio)
            indices_to_augment = set(np.random.choice(
                total_images, 
                min(num_to_augment, total_images), 
                replace=False
            ))
        else:  # "deterministic"
            if num_to_augment is None:
                num_to_augment = int(total_images * augmentation_ratio)
            
            if total_images <= num_to_augment:
                indices_to_augment = set(range(total_images))
            else:
                step = total_images / num_to_augment
                indices_to_augment = set()
                for i in range(num_to_augment):
                    idx = int(i * step)
                    indices_to_augment.add(min(idx, total_images - 1))
        
        # å¤„ç†å›¾åƒ
        processed_count = 0
        augmented_count = 0
        failed_count = 0
        skipped_count = 0
        
        for idx, filename in enumerate(all_images):
            image_path = images_path / filename
            apply_augmentation = idx in indices_to_augment
            
            try:
                if not image_path.exists():
                    skipped_count += 1
                    continue
                
                # è¯»å–å›¾åƒ
                image = cv2.imread(str(image_path), cv2.IMREAD_UNCHANGED)
                if image is None:
                    failed_count += 1
                    print(f"âš ï¸ æ— æ³•è¯»å–å›¾åƒ: {filename}")
                    continue
                
                # å¤‡ä»½åŸå›¾
                if backup_original:
                    backup_path = image_path.with_suffix(image_path.suffix + '.bak')
                    if not backup_path.exists():
                        import shutil
                        shutil.copy2(image_path, backup_path)
                
                # åº”ç”¨å¢å¼º
                if apply_augmentation:
                    enhanced_image = apply_enhancements(image, random_seed=idx)  # æ¯å¼ å›¾ç”¨ä¸åŒç§å­é¿å…å®Œå…¨ç›¸åŒ
                    cv2.imwrite(str(image_path), enhanced_image, [cv2.IMWRITE_PNG_COMPRESSION, 3])
                    augmented_count += 1
                
                processed_count += 1
                    
            except Exception as e:
                print(f"âŒ å¤„ç†å¤±è´¥ {filename}: {e}")
                failed_count += 1
            
            # è¿›åº¦æ˜¾ç¤º
            if processed_count % 50 == 0:
                print(f"ğŸ“Š è¿›åº¦: {processed_count}/{total_images} (å·²å¢å¼º: {augmented_count})")
        
        result = (
            f"âœ… å›¾åƒå¢å¼ºå®Œæˆï¼ï¼ˆåŸåœ°æ›¿æ¢ï¼‰\n"
            f"ğŸ“Š æ€»å›¾ç‰‡: {total_images}\n"
            f"ğŸ”„ å·²å¢å¼º: {augmented_count}\n"
            f"âŒ å¤„ç†å¤±è´¥: {failed_count}\n"
            f"ğŸ¯ ç­–ç•¥: {enhance_strategy}\n"
            f"ğŸ”§ éšæœºç§å­: {random_seed}\n"
            f"ğŸ“ ç›®å½•: {images_dir}\n"
        )
        
        if skipped_count > 0:
            result += f"âš ï¸ è·³è¿‡: {skipped_count} å¼ ï¼ˆå¯èƒ½ä¸åœ¨ JSONL ä¸­ï¼‰\n"
        
        if dataset_jsonl:
            result += f"ğŸ“‹ å‚è€ƒ JSONL: {dataset_jsonl}\n"
        
        return result
        
    except Exception as e:
        return f"âŒ å¢å¼ºå¤±è´¥: {str(e)}"

# å…¶ä»–å‡½æ•°ä¿æŒä¸å˜...
def enhance_images_to_new_dir(
    input_dir: str,
    output_dir: str,
    dataset_jsonl: str = None,
    num_to_augment: int = None,
    augmentation_ratio: float = 0.1,
    enhance_strategy: str = "deterministic",
    random_seed: int = 42
) -> str:
    """å¢å¼ºå›¾ç‰‡åˆ°æ–°ç›®å½•"""
    try:
        input_path = Path(input_dir)
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)
        
        # è·å–å›¾ç‰‡åˆ—è¡¨
        supported_formats = {'.png', '.jpg', '.jpeg', '.bmp', '.tiff', '.gif'}
        
        if dataset_jsonl and Path(dataset_jsonl).exists():
            jsonl_images = _get_images_from_jsonl(dataset_jsonl)
            all_images = []
            for file in input_path.iterdir():
                if file.suffix.lower() in supported_formats and file.name in jsonl_images:
                    all_images.append(file.name)
        else:
            all_images = []
            for file in input_path.iterdir():
                if file.suffix.lower() in supported_formats:
                    all_images.append(file.name)
        
        if not all_images:
            return f"âŒ è¾“å…¥ç›®å½•ä¸­æ²¡æœ‰æ‰¾åˆ°å›¾ç‰‡æ–‡ä»¶"
        
        all_images.sort()
        
        # ç¡®å®šè¦å¢å¼ºçš„å›¾ç‰‡ç´¢å¼•
        np.random.seed(random_seed)
        total_images = len(all_images)
        
        if enhance_strategy == "all":
            indices_to_augment = set(range(total_images))
        elif enhance_strategy == "random":
            if num_to_augment is None:
                num_to_augment = int(total_images * augmentation_ratio)
            indices_to_augment = set(np.random.choice(
                total_images, 
                min(num_to_augment, total_images), 
                replace=False
            ))
        else:
            if num_to_augment is None:
                num_to_augment = int(total_images * augmentation_ratio)
            
            if total_images <= num_to_augment:
                indices_to_augment = set(range(total_images))
            else:
                step = total_images / num_to_augment
                indices_to_augment = set()
                for i in range(num_to_augment):
                    idx = int(i * step)
                    indices_to_augment.add(min(idx, total_images - 1))
        
        # å¤„ç†å›¾åƒ
        processed_count = 0
        augmented_count = 0
        failed_count = 0
        
        for idx, filename in enumerate(all_images):
            input_path_file = input_path / filename
            output_path_file = output_path / filename
            apply_augmentation = idx in indices_to_augment
            
            try:
                image = cv2.imread(str(input_path_file), cv2.IMREAD_UNCHANGED)
                if image is None:
                    failed_count += 1
                    continue
                
                if apply_augmentation:
                    enhanced_image = apply_enhancements(image, random_seed=idx)
                    cv2.imwrite(str(output_path_file), enhanced_image, [cv2.IMWRITE_PNG_COMPRESSION, 3])
                    augmented_count += 1
                else:
                    import shutil
                    shutil.copy2(input_path_file, output_path_file)
                
                processed_count += 1
                    
            except Exception as e:
                print(f"âŒ å¤„ç†å¤±è´¥ {filename}: {e}")
                failed_count += 1
        
        return (
            f"âœ… å›¾åƒå¢å¼ºå®Œæˆï¼ï¼ˆå¤åˆ¶åˆ°æ–°ç›®å½•ï¼‰\n"
            f"ğŸ“Š æ€»å›¾ç‰‡: {total_images}\n"
            f"ğŸ”„ å·²å¢å¼º: {augmented_count}\n"
            f"âŒ å¤„ç†å¤±è´¥: {failed_count}\n"
            f"ğŸ”§ éšæœºç§å­: {random_seed}\n"
            f"ğŸ“ è¾“å…¥ç›®å½•: {input_dir}\n"
            f"ğŸ“ è¾“å‡ºç›®å½•: {output_dir}\n"
        )
        
    except Exception as e:
        return f"âŒ å¢å¼ºå¤±è´¥: {str(e)}"

def enhance_images_with_backup(
    images_dir: str,
    output_dir: str = None,
    dataset_jsonl: str = None,
    num_to_augment: int = None,
    augmentation_ratio: float = 0.1,
    enhance_strategy: str = "deterministic",
    random_seed: int = 42
) -> str:
    """å¢å¼ºå›¾ç‰‡ï¼ˆæ”¯æŒå¤‡ä»½æ¨¡å¼ï¼‰"""
    if output_dir:
        return enhance_images_to_new_dir(
            images_dir, output_dir, dataset_jsonl, 
            num_to_augment, augmentation_ratio, enhance_strategy, random_seed
        )
    else:
        return enhance_images_in_place(
            images_dir, dataset_jsonl,
            num_to_augment, augmentation_ratio, enhance_strategy, 
            random_seed=random_seed  # æ–°å¢éšæœºç§å­å‚æ•°
        )